---
title: "VLA Survey"
date: 2025-11-04
tags: [Dynamics, robotics]
toc: true
mathjax: true
---

# Vision–Language–Action( VLA ) 로보틱스 서베이 핵심 요약

> 원문: *Vision‑Language‑Action Models for Robotics: A Review Towards Real‑World Applications* (IEEE Access, 2025)

## TL;DR

* VLA의 정의: 시각(vision) + 언어(language) 입력을 받아 직접 로봇 제어 명령(action) 을 생성하는 모델. 단순한 스킬 선택자는 제외.
* 핵심 난제: (1) 삼중 모달(비전·언어·액션) 정렬 데이터 부족, (2) 크로스‑엠보디먼트 전이(로봇/사람/형상 차이), (3) 훈련·추론 연산비용.
* 설계 트렌드: CNN→트랜스포머→VLM 백본 + 연속 제어(디퓨전/플로우매칭) → 계층형 정책(고수준 계획 + 저수준 제어).
* 실무 가이드: (i) 다양한 고품질 데이터, (ii) 연속 제어 생성기(디퓨전/플로우) 채택, (iii) 백본 보호(그라디언트 절연/동결), (iv) 경량 미세조정(LoRA 등), (v) 월드모델/잠재액션 활용.

---

## 왜 중요한가

* VLA는 새 작업·새 환경으로의 일반화를 목표로 하며, 태스크별 파이프라인/데이터 수집 비용을 줄여 현실 배치 가능성을 끌어올린다.
* 기존 "VLM으로 계획 + 별도 제어기" 방식의 한계를 넘어, 엔드투엔드 센서‑모터 연결을 강화한다.

---

## 시대별 주요 모델 이정표 (왜 중요한가)

1. CLIPort — CLIP와 트랜스포터 네트워크로 텍스트‑조건 조작을 엔드투엔드로 시연. *초기 VLA 가능성 입증.*
2. Gato / VIMA — 멀티태스크 시퀀스 트랜스포머로 텍스트·이미지·액션을 토크나이즈해 자기회귀 예측. *범용성 개념 확장(주로 시뮬/제한 작업).*
3. RT‑1 → RT‑2 → RT‑X — 실세계 대규모 시演. RT‑2는 대규모 VLM 백본(PaLM‑E/PaLI‑X)을 로봇 데이터와 공학습하여 상식·인컨텍스트 강점과 실세계 일반화를 결합. RT‑X는 다수 로봇 데이터 융합의 이점을 제시. *실사용 스케일의 분기점.*
4. OpenVLA — RT‑2 계열의 오픈소스 구현/학습 레시피. OXE 데이터셋 기반 풀 파인튜닝으로 동급 대비 우수 성능 보고. *재현성·연구 가속.*
5. Octo — 디퓨전 정책으로 부드럽고 안정적인 연속 제어. *토큰 이산화 한계를 보완.*
6. RDT‑1B — 디퓨전 트랜스포머(백본‑내 확산) 로 동작 시퀀스를 생성. *확산을 액션헤드가 아닌 모델 본체에 통합.*
7. π0 — 플로우 매칭 기반 액션 전문가로 50Hz급 실시간 연속 제어. *실시간성 향상 트렌드의 대표.*
8. LAPA — 대규모 사람 비디오에서 잠재 액션을 학습해 로봇에 전이. *엠보디먼트 차이·레이블 부족 타개.*
9. RT‑H / π0.5 / GR00T N1 — 계층형 정책(언어‑기반 고수준 계획 + 연속 저수준 제어)으로 장기 과제 성능 향상. *현재 SOTA 설계 패턴.*

> 요약: 오늘날 주류는 VLM 백본 + (디퓨전/플로우) 연속 제어 + 계층화이며, 인간·다로봇 데이터를 광범위하게 활용한다.

---

## 설계·학습 빌딩블록 한눈에

* 비전 인코더: SigLIP, DINOv2, ViT/ResNet (+토큰 압축: Perceiver Resampler, Q‑Former, TokenLearner).
* 언어 인코더/백본: LLaMA 계열, T5, Gemma, Qwen 등 대규모 VLM.
* 액션 표현: (a) 이산 비닝 토큰(FAST로 시퀀스 압축), (b) 토큰→MLP 연속 출력, (c) 디퓨전/플로우 연속 생성, (d) 잠재 액션(VQ‑VAE 등) 학습, (e) 크로스‑엠보디먼트 UAS/전용 헤드.
* 대체/보강 모달리티: 포인트클라우드/깊이/멀티뷰, 오디오, 촉각/포스 등.
* 월드모델: 미래 관측(영상/잠재)을 예측해 계획·추론을 보조(예: UniPi, MinD, FLARE 등).
* CoT/계층화: 중간 표상(서브태스크, 서브골 이미지, 언어‑모션 등)로 안정적 장기 계획.

---

## 실무 체크리스트 (저자 권고를 실천 항목으로)

* 데이터 다변화: 비전·언어·액션이 정렬된 대규모·고품질 데이터로 태스크/환경/엠보디먼트를 넓혀라.
* 연속 제어 채택: 실제 로봇에선 디퓨전/플로우 방식이 매끄럽고 정밀한 트래젝토리를 제공.
* 백본 보호: 초기 액션헤드의 잡음이 VLM 의미표상을 망치지 않게 동결/그라디언트 절연을 적용.
* 경량 어댑트: 먼저 액션헤드만 또는 LoRA로 미세조정 → 필요 시 전체 미세조정.
* 월드모델·잠재액션: 사람 비디오를 활용하려면 잠재 액션 학습을 통해 레이블 없이도 스케일링.
* 멀티태스크 보조목표: 어포던스/키포인트/미래상태/세그먼트 예측을 함께 학습해 행동 친화 표상을 강화.

---

## 평가·데이터(간단 가이드)

* 학습 데이터: 다로봇 융합(예: OXE 형식), 텔레옵/EBC, 인간 시연(잠재액션) 혼합.
* 벤치마크: 장기 태스크·조작 난이도·일반화(신규 물체/장면/로봇) 항목을 포함하는 리얼월드 중심 프로토콜 권장.

---

## 열려 있는 연구 과제

* 엠보디먼트 전이의 근본적 해결(로봇·인간·이기종 센서/조인트 정합).
* 효율성: 긴 시퀀스·고해상도 입력에서도 저지연·저메모리 추론.
* 신뢰성·안전성: 실패 예측, 불확실성 추정, 휴먼‑인더루프 보정.
* 스케일링 로드맵: 월드모델·잠재액션과 RL/온라인 적응의 결합 최적화.

---

## 지금 읽어야 할 대표 논문 Quick List

* RT‑1/RT‑2/RT‑X — 대규모 실세계 시연과 VLM 결합의 전범.
* OpenVLA — 재현성 높은 오픈 프레임워크.
* Octo / RDT‑1B — 디퓨전 정책·디퓨전 트랜스포머의 대표.
* π0 / π0.5 — 플로우 매칭 기반 고주파 제어 및 계층형 통합.
* LAPA — 사람 비디오로 잠재 액션 학습.
* RT‑H / GR00T N1 — 계층형 정책 SOTA 설계.

> 위 논문군을 이 순서로 보면, 역사→백본→연속제어→계층화→잠재학습까지 현재 메인스트림을 빠르게 포괄할 수 있다.
